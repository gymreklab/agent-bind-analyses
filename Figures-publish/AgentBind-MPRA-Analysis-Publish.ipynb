{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains a comparison of AgentBind to MPRA data from Tewhey et al. Cell 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import sklearn.metrics\n",
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "data = pd.read_csv(\"../mpra/Tewhey_MPRA_hg19.tab\", sep=\"\\t\")\n",
    "data[\"chrom\"] = data[\"chrom\"].apply(lambda x: \"chr\"+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FOS\n",
      "STAT1\n",
      "CEBPB\n",
      "JunD\n",
      "STAT3\n",
      "RFX5\n",
      "ETS1\n",
      "NFYA\n",
      "CTCF\n",
      "EBF1\n",
      "SP1\n",
      "PU1\n",
      "RUNX3\n",
      "NFYB\n",
      "Nrf1\n",
      "ELF1\n",
      "NFKB\n",
      "TCF3\n",
      "Mxi1\n",
      "USF1\n",
      "YY1\n",
      "USF2\n",
      "ZEB1\n",
      "PAX5\n",
      "POU2F2\n",
      "NRSF\n",
      "PBX3\n",
      "MEF2A\n",
      "E2F4\n",
      "BHLHE40\n",
      "ELK1\n",
      "NFIC\n",
      "MEF2C\n",
      "Max\n",
      "SRF\n",
      "Znf143\n",
      "IRF4\n",
      "ZBTB33\n"
     ]
    }
   ],
   "source": [
    "factors_str = \"FOS STAT1 CEBPB JunD STAT3 RFX5 ETS1 NFYA CTCF EBF1 SP1 \\\n",
    "PU1 RUNX3 NFYB Nrf1 ELF1 NFKB TCF3 Mxi1 USF1 YY1 USF2 ZEB1 PAX5 POU2F2 \\\n",
    "NRSF PBX3 MEF2A E2F4 BHLHE40 ELK1 NFIC MEF2C Max SRF Znf143 IRF4 ZBTB33\"\n",
    "#factors_str = \"FOS\" # this line is for testing only\n",
    "factors = factors_str.split()\n",
    "\n",
    "model = \"dnase-controlled\"\n",
    "#model = \"baseline\"\n",
    "#model = \"gc-controlled\"\n",
    "\n",
    "if model == \"dnase-controlled\":\n",
    "    experiment = \"AgentBind-GM12878-DanQ-trainon-DNase-GC-balanced\"\n",
    "if model == \"gc-controlled\":\n",
    "    experiment = \"AgentBind-GM12878-DanQ-unfixed-rnn-trans-GC-balanced\"\n",
    "if model == \"baseline\":\n",
    "    experiment = \"AgentBind-GM12878-DanQ-unfixed-rnn-trans\"\n",
    "\n",
    "chrom_ = []\n",
    "pos_ = []\n",
    "factor_ = []\n",
    "score_ = []\n",
    "rank_ = []\n",
    "score_norm_ = []\n",
    "\n",
    "version = \"equal\"\n",
    "\n",
    "if version == \"plus1\":\n",
    "    data[\"pos2\"] = data[\"pos\"]+1 # TODO figure out offset (so far -1 is best)\n",
    "if version == \"minus1\":\n",
    "    data[\"pos2\"] = data[\"pos\"]-1\n",
    "if version == \"equal\":\n",
    "    data[\"pos2\"] = data[\"pos\"]\n",
    "\n",
    "def GetRank(vallist, val):\n",
    "    slist = sorted(vallist)\n",
    "    return slist.index(val)\n",
    "    \n",
    "\n",
    "for factor in factors:\n",
    "    print (factor)\n",
    "    position_line = True\n",
    "    weight_file = \"/storage/pandaman/project/%s/storage/AgentBind-GM12878-DanQ/tmp/%s+GM12878/seqs_one_hot_c/vis-weights-total/weight.txt\" %(experiment, factor)\n",
    "    for line in open(weight_file):\n",
    "        if position_line:\n",
    "            chromID, motif_start, motif_end, seq_start, seq_end, strand = line.strip().split(\";\")\n",
    "            motif_start = int(motif_start)\n",
    "            motif_end = int(motif_end)\n",
    "            seq_start = int (seq_start)\n",
    "            seq_end = int(seq_end)\n",
    "            position_line = False\n",
    "        else:\n",
    "            weights = [float(elem) for elem in line.strip().split(\";\")]\n",
    "            region_snps = list(data[(data[\"chrom\"]==chromID) & (data[\"pos2\"]>=seq_start) & (data[\"pos2\"]<seq_end)][\"pos2\"].values)\n",
    "            other_snps = []\n",
    "            for item in region_snps:\n",
    "                other_snps.append(item+1)\n",
    "                other_snps.append(item-1)\n",
    "            for pos in region_snps+other_snps:\n",
    "                try:\n",
    "                    if strand == \"+\":\n",
    "                        score_pred = weights[pos - seq_start]\n",
    "                    elif strand == \"-\":\n",
    "                        score_pred = weights[1000 - (pos - seq_start) - 1]\n",
    "                    else:\n",
    "                        print(\"Incorrect symbol: %s\" %strand)\n",
    "                        continue\n",
    "                except: continue\n",
    "                score_rank = GetRank(weights, score_pred)\n",
    "                # Add to list\n",
    "                chrom_.append(chromID)\n",
    "                pos_.append(pos)\n",
    "                factor_.append(factor)\n",
    "                score_.append(score_pred)\n",
    "                score_norm_.append(score_pred/np.mean(weights))\n",
    "                rank_.append(score_rank)\n",
    "            position_line = True\n",
    "            \n",
    "gcam = pd.DataFrame({\"chrom\": chrom_, \"rank\": rank_, \"pos2\": pos_, \"factor\": factor_, \"score\": score_, \"score.norm\": score_norm_})\n",
    "gcam.to_csv(\"gcam_scores_%s_%s.csv\"%(version, model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do analysis overall and by TF\n",
    "\n",
    "factors_str = \"FOS STAT1 CEBPB JunD STAT3 RFX5 ETS1 NFYA CTCF EBF1 SP1 \\\n",
    "PU1 RUNX3 NFYB Nrf1 ELF1 NFKB TCF3 Mxi1 USF1 YY1 USF2 ZEB1 PAX5 POU2F2 \\\n",
    "NRSF PBX3 MEF2A E2F4 BHLHE40 ELK1 NFIC MEF2C Max SRF Znf143 IRF4 ZBTB33\"\n",
    "#factors_str = \"FOS\" # this line is for testing only\n",
    "factors = factors_str.split()\n",
    "\n",
    "model = \"dnase-controlled\"\n",
    "gcam = pd.read_csv(\"gcam_scores_equal_%s.csv\"%model)\n",
    "\n",
    "def GetBest(scores):\n",
    "    best = 0 #scores.values[0]\n",
    "    for item in scores:\n",
    "        if item > best: best = item\n",
    "    return best\n",
    "\n",
    "data[\"pos2\"] = data[\"pos\"]+1\n",
    "\n",
    "\n",
    "score_corr_ = []\n",
    "score_corr_p_ = []\n",
    "rank_corr_ = []\n",
    "rank_corr_p_ = []\n",
    "num_emvars_ = []\n",
    "auc_score_ = []\n",
    "auc_rank_ = []\n",
    "auc_norm_ = []\n",
    "auprc_score_ = []\n",
    "\n",
    "FDRTHRESH = 0.05\n",
    "\n",
    "aucinfo = {}\n",
    "auprcinfo = {}\n",
    "\n",
    "for factor in [\"ALL\"]+factors:\n",
    "    if factor == \"ALL\":\n",
    "        comp = pd.merge(data, gcam, on=[\"chrom\",\"pos2\"]).groupby([\"chrom\",\"pos\"], as_index=False).agg(\n",
    "            {\"score\": GetBest, \"score.norm\": np.max, \"rank\": np.max,\n",
    "            \"LogSkew.Comb\": np.mean, \"C.Skew.fdr\": np.mean})\n",
    "    else:\n",
    "        comp = pd.merge(data, gcam[gcam[\"factor\"]==factor], on=[\"chrom\",\"pos2\"]).groupby([\"chrom\",\"pos\"], as_index=False).agg(\n",
    "            {\"score\": GetBest, \"score.norm\": np.max, \"rank\": np.max,\n",
    "            \"LogSkew.Comb\": np.mean, \"C.Skew.fdr\": np.mean})\n",
    "    comp = comp[~np.isnan(comp[\"C.Skew.fdr\"])] # restrict to \"RegHits\"\n",
    "    comp[\"LogSkew.Comb.abs\"] = comp[\"LogSkew.Comb\"].apply(abs)\n",
    "    comp = comp[comp[\"score\"]>0] # remove things with weird gcam scores\n",
    "\n",
    "    emv = comp[(comp[\"C.Skew.fdr\"]>-1*np.log10(FDRTHRESH)) ] # log10?\n",
    "\n",
    "    num_emvars_.append(emv.shape[0])\n",
    "\n",
    "    if factor == \"ALL\":\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.scatter(emv[\"LogSkew.Comb.abs\"], emv[\"score\"].apply(abs))\n",
    "        ax.set_ylim(bottom=-0.00005, top=0.001)\n",
    "        ax.set_title(factor)\n",
    "    xx = scipy.stats.spearmanr(emv[\"LogSkew.Comb.abs\"], emv[\"score\"].apply(abs))\n",
    "    score_corr_.append(xx[0])\n",
    "    score_corr_p_.append(xx[1])\n",
    "    \n",
    "    xx = (scipy.stats.spearmanr(emv[\"LogSkew.Comb.abs\"], emv[\"rank\"]))\n",
    "    rank_corr_.append(xx[0])\n",
    "    rank_corr_p_.append(xx[1])\n",
    "\n",
    "\n",
    "    comp[\"emvar\"] = (comp[\"C.Skew.fdr\"]>-1*np.log10(FDRTHRESH))\n",
    "\n",
    "    if comp.shape[0] > 5:\n",
    "        if factor == \"ALL\":\n",
    "            comp.boxplot(by=\"emvar\", column=\"score\", sym=\"\")\n",
    "            print(scipy.stats.mannwhitneyu(comp[comp[\"emvar\"]][\"score\"],\n",
    "                                           comp[~comp[\"emvar\"]][\"score\"]))\n",
    "            print(len(comp[comp[\"emvar\"]][\"score\"]))\n",
    "            print(len(comp[~comp[\"emvar\"]][\"score\"]))\n",
    "\n",
    "        # Get auroc\n",
    "        fpr, tpr, thresholds = sklearn.metrics.roc_curve(comp[\"emvar\"], comp[\"score\"], pos_label=True)\n",
    "        auc_score_.append(sklearn.metrics.auc(fpr, tpr))\n",
    "        aucinfo[factor] = (fpr, tpr)\n",
    "        precision, recall, thresholds = sklearn.metrics.precision_recall_curve(comp[\"emvar\"], comp[\"score\"], pos_label=True)\n",
    "        auprcinfo[factor] = (precision, recall)                                                                       \n",
    "        auprc_score_.append(sklearn.metrics.average_precision_score(comp[\"emvar\"], comp[\"score\"], pos_label=True))\n",
    "                                                                               \n",
    "        fpr, tpr, thresholds = sklearn.metrics.roc_curve(comp[\"emvar\"], comp[\"rank\"], pos_label=True)\n",
    "        auc_rank_.append(sklearn.metrics.auc(fpr, tpr))\n",
    "        fpr, tpr, thresholds = sklearn.metrics.roc_curve(comp[\"emvar\"], comp[\"score.norm\"], pos_label=True)\n",
    "        auc_norm_.append(sklearn.metrics.auc(fpr, tpr))\n",
    "\n",
    "    else:\n",
    "        auc_score_.append(float(\"nan\"))\n",
    "        auc_rank_.append(float(\"nan\"))\n",
    "        auc_norm_.append(float(\"nan\"))\n",
    "        auprc_score_.append(float(\"nan\"))\n",
    "\n",
    "res = pd.DataFrame({\"factor\": [\"ALL\"]+factors,\n",
    "                   \"r.score\": score_corr_,\n",
    "                   \"r.score.p\": score_corr_p_,\n",
    "                   \"r.rank\": rank_corr_,\n",
    "                   \"r.rank.p\": rank_corr_p_,\n",
    "                   \"num.emvar\": num_emvars_,\n",
    "                   \"auc.score\": auc_score_,\n",
    "                   \"auc.rank\": auc_rank_,\n",
    "                   \"auc.norm\": auc_norm_,\n",
    "                   \"auprc.score\": auprc_score_})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
